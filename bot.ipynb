{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.tools import tool\n",
    "from langchain_community.tools.yahoo_finance_news import YahooFinanceNewsTool\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent(tools: list, system_prompt: str):\n",
    "          prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "              (\"system\", system_prompt),\n",
    "              MessagesPlaceholder(variable_name=\"messages\"),\n",
    "              MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "            ]\n",
    "          )\n",
    "          llm = OllamaFunctions(model=\"phi3\", format=\"json\")\n",
    "          agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "          return AgentExecutor(agent=agent, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_supervisor(agents: list[str]):\n",
    "          llm = OllamaFunctions(model=\"phi3\", format=\"json\")\n",
    "          system_prompt = (\n",
    "            \"You are the supervisor over the following agents: {agents}.\"\n",
    "            \" You are responsible for assigning tasks to each agent as requested by the user.\"\n",
    "            \" Each agent executes tasks according to their roles and responds with their results and status.\"\n",
    "            \" Please review the information and answer with the name of the agent to which the task should be assigned next.\"\n",
    "            \" Answer 'FINISH' if you are satisfied that you have fulfilled the user's request.\"\n",
    "          )\n",
    "\n",
    "          options = [\"FINISH\"] + agents\n",
    "          function_def = {\n",
    "            \"name\": \"supervisor\",\n",
    "            \"description\": \"Select the next agent.\",\n",
    "            \"parameters\": {\n",
    "              \"type\": \"object\",\n",
    "              \"properties\": {\n",
    "                \"next\": {\n",
    "                  \"anyOf\": [\n",
    "                    {\"enum\": options},\n",
    "                  ],\n",
    "                }\n",
    "              },\n",
    "              \"required\": [\"next\"],\n",
    "            },\n",
    "          }\n",
    "\n",
    "          prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "              (\"system\", system_prompt),\n",
    "              MessagesPlaceholder(variable_name=\"messages\"),\n",
    "              (\n",
    "                \"system\",\n",
    "                \"In light of the above conversation, please select one of the following options for which agent should be act or end next: {options}.\"\n",
    "              ),\n",
    "            ]\n",
    "          ).partial(options=str(options), agents=\", \".join(agents))\n",
    "\n",
    "          return (\n",
    "            prompt\n",
    "            | llm.bind_tools(tools=[function_def], function_call=\"supervisor\")\n",
    "            | JsonOutputParser()\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"Trading_Research\")\n",
    "def researcher(query: str) -> str:\n",
    "    \"\"\"Research by Yahoo\"\"\"\n",
    "    Yfinance = YahooFinanceNewsTool()\n",
    "    return Yfinance.run(query)\n",
    "\n",
    "@tool(\"Market Analysist\")\n",
    "def analyze(content: str) -> str:\n",
    "    \"\"\"Market Analyser\"\"\"\n",
    "    chat = OllamaFunctions(model=\"phi3\", format=\"json\")\n",
    "    messages = [\n",
    "    SystemMessage(\n",
    "    content=\"Act as a day trading assistant. Your task is to identify trading assets that meet the specified{User_input}\"\n",
    "            \"Utilize your expertise and available market analysis tools to scan, filter, and evaluate potential assets for trading.\" \n",
    "            \"Once identified, create a comprehensive list with supporting data for each asset, indicating why it meets the criteria. \"\n",
    "            \"Ensure that all information is up-to-date and relevant to the current market conditions. \"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=content\n",
    "    ),\n",
    "    ]\n",
    "    response = chat(messages)\n",
    "    return response.content\n",
    "\n",
    "@tool(\"Trade Execution\")\n",
    "def executer(content: str) -> str:\n",
    "    \"\"\"Execute a trade\"\"\"\n",
    "    chat = OllamaFunctions(model=\"phi3\", format=\"json\")\n",
    "    messages = [\n",
    "    SystemMessage(\n",
    "    content=\"Act as an experienced trading assistant. Based on your comprehensive analysis of current market conditions,\"\n",
    "            \"historical data, and emerging trends, decide on optimal entry, stop-loss, and target points for a specified \"\n",
    "            \"trading asset. Begin by thoroughly reviewing recent price action, key technical indicators, and relevant news\"\n",
    "            \"that might influence the asset's direction.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=content\n",
    "    ),\n",
    "    ]\n",
    "    response = chat(messages)\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import Runnable\n",
    "\n",
    "llm = OllamaFunctions(model=\"phi3\", format=\"json\")\n",
    "\n",
    "def researcher_agent() -> Runnable:\n",
    "  prompt = (\n",
    "    \"You are an Trader research assistant, you uses Yahoo Fiance News to find the most up-to-date and correct information.\"\n",
    "    \"Your research should be rigorous, data-driven, and well-documented\"\n",
    "  )\n",
    "  return create_agent(llm, [researcher], prompt)\n",
    "\n",
    "def analyzer_agent() -> Runnable:\n",
    "  prompt = (\n",
    "    \"As a Market Stock Analyzer, your main job is to study the stock market and \"\n",
    "    \"help people make smart decisions about their investments \"\n",
    "  )\n",
    "  return create_agent(llm, [analyze], prompt)\n",
    "\n",
    "def executor_agent() -> Runnable:\n",
    "  prompt = (\n",
    "    \"You are a Executor in the stock market, your job is to help people invest their money wisely.\"\n",
    "    \"You study how the stock market works and figure out which companies are good to invest in.\"\n",
    "  )\n",
    "  return create_agent(llm, [analyze], prompt)\n",
    "\n",
    "\n",
    "\n",
    "RESEARCHER = \"RESEARCHER\"\n",
    "ANALYZER = \"Analyzer\"\n",
    "EXECUTOR = \"Executor\"\n",
    "SUPERVISOR = \"SUPERVISOR\"\n",
    "\n",
    "agents = [RESEARCHER, ANALYZER, EXECUTOR]\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "  messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "  next: str\n",
    "\n",
    "def researcher_node(state: AgentState) -> dict:\n",
    "  result = researcher_agent().invoke(state)\n",
    "  return {\"messages\": [HumanMessage(content=result[\"output\"], name=RESEARCHER)]}\n",
    "\n",
    "def Analyzer_node(state: AgentState) -> dict:\n",
    "  result = Analyzer_node().invoke(state)\n",
    "  return {\"messages\": [HumanMessage(content=result['output'], name=ANALYZER)]}\n",
    "\n",
    "def Executor_node(state: AgentState) -> dict: \n",
    "  result = executor_agent().invoke(state)\n",
    "  return {\"messages\":[HumanMessage(content=result[\"output\"], name=EXECUTOR)]}\n",
    "\n",
    "def supervisor_node(state: AgentState) -> Runnable:\n",
    "  return create_supervisor(agents)\n",
    "\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(RESEARCHER,researcher_node)\n",
    "workflow.add_node(ANALYZER,Analyzer_node)\n",
    "workflow.add_node(EXECUTOR, Executor_node)\n",
    "workflow.add_node(SUPERVISOR, supervisor_node)\n",
    "\n",
    "workflow.add_edge(RESEARCHER, SUPERVISOR)\n",
    "workflow.add_edge(ANALYZER, SUPERVISOR)\n",
    "workflow.add_edge(EXECUTOR,SUPERVISOR)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "  SUPERVISOR,\n",
    "  lambda x: x[\"next\"],\n",
    "  {\n",
    "    RESEARCHER: RESEARCHER,\n",
    "    ANALYZER: ANALYZER,\n",
    "    EXECUTOR : EXECUTOR,\n",
    "    \"FINISH\" : END\n",
    "  }\n",
    ")\n",
    "\n",
    "workflow.set_entry_point(SUPERVISOR)\n",
    "\n",
    "graph = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input=\"which stock is on top ?\"\n",
    "for s in graph.stream({\"messages\" : [HumanMessage(content=user_input)]}):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
